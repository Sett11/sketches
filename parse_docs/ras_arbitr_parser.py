#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
RAS Arbitr Parser v2.0 - –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø
–ü–∞—Ä—Å–∏–Ω–≥ ras.arbitr.ru —Å –ø–µ—Ä–µ—Ö–≤–∞—Ç–æ–º XHR —á–µ—Ä–µ–∑ CDP

–û—Å–Ω–æ–≤–Ω—ã–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è:
1. –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π URL: https://ras.arbitr.ru/#searchPrintForm
2. –û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ SPA –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
3. –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –º–µ—Ç–æ–¥—ã –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –ø–æ–ª–µ–π
4. –£–ª—É—á—à–µ–Ω–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞
"""

import os
import json
import time
import random
import logging
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Optional

from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.common.action_chains import ActionChains
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException

# curl_cffi –¥–ª—è –≤–Ω–µ—à–Ω–∏—Ö POST –∑–∞–ø—Ä–æ—Å–æ–≤ (–∑–∞–ø–∞—Å–Ω–æ–π –º–µ—Ç–æ–¥)
try:
    from curl_cffi import requests as curl_requests
    CURL_CFFI_AVAILABLE = True
except ImportError:
    CURL_CFFI_AVAILABLE = False
    logger.warning("‚ö†Ô∏è curl_cffi –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –í–Ω–µ—à–Ω–∏–µ POST –∑–∞–ø—Ä–æ—Å—ã –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã.")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('ras_parser.log', encoding='utf-8', mode='a'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è - –ò–°–ü–†–ê–í–õ–ï–ù–û
RAS_HOME = "https://ras.arbitr.ru/"
RAS_SEARCH_PAGE = "https://ras.arbitr.ru/#searchPrintForm"  # –°—Ç—Ä–∞–Ω–∏—Ü–∞ —Å —Ñ–æ—Ä–º–æ–π –ø–æ–∏—Å–∫–∞
SEARCH_URL = "https://ras.arbitr.ru/Ras/Search"
# –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ PDF –≤ –ª–æ–∫–∞–ª—å–Ω—É—é –ø–∞–ø–∫—É –ø—Ä–æ–µ–∫—Ç–∞ "res"
PROJECT_ROOT = Path(__file__).resolve().parents[1]
SAVE_DIR = str((PROJECT_ROOT / "res").resolve())
KAD_HOME = "https://kad.arbitr.ru/"
PDF_DIR = str((Path(SAVE_DIR) / "pdf").resolve())
os.makedirs(SAVE_DIR, exist_ok=True)
os.makedirs(PDF_DIR, exist_ok=True)
os.makedirs(SAVE_DIR, exist_ok=True)

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∞–Ω—Ç–∏–±–∞–Ω–∞
BASE_DELAY = 10  # –±–∞–∑–æ–≤–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
JITTER = 3  # —Å–ª—É—á–∞–π–Ω—ã–π –¥–∂–∏—Ç—Ç–µ—Ä
LONG_PAUSE_EVERY = 5  # –¥–ª–∏–Ω–Ω–∞—è –ø–∞—É–∑–∞ –∫–∞–∂–¥—ã–µ N –∑–∞–ø—Ä–æ—Å–æ–≤
LONG_PAUSE_RANGE = (40, 90)  # –¥–∏–∞–ø–∞–∑–æ–Ω –¥–ª–∏–Ω–Ω–æ–π –ø–∞—É–∑—ã
PREWARM_EVERY = 3  # –ø—Ä–æ–≥—Ä–µ–≤ –≥–ª–∞–≤–Ω–æ–π –∫–∞–∂–¥—ã–µ N –∑–∞–ø—Ä–æ—Å–æ–≤

logger.info("="*60)
logger.info("üöÄ RAS Arbitr Parser v2.0 - –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø")
logger.info("="*60)
logger.info("‚úÖ –ú–æ–¥—É–ª–∏ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã")
print("\nüöÄ –ü–∞—Ä—Å–µ—Ä RAS Arbitr –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ")
print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {SAVE_DIR}\n")


class RasArbitrParser:
    """–ö–ª–∞—Å—Å –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –±—Ä–∞—É–∑–µ—Ä–æ–º —Å CDP –ø–µ—Ä–µ—Ö–≤–∞—Ç–æ–º - –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø"""
    
    def __init__(self):
        self.driver = None
        self.cdp_responses = []
        self.xhr_captured = []
        
    def build_driver(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ Chrome –¥—Ä–∞–π–≤–µ—Ä–∞ —Å CDP"""
        options = Options()
        options.add_argument("--start-maximized")
        options.add_argument("--no-sandbox")
        options.add_argument("--disable-dev-shm-usage")
        options.add_argument("--disable-popup-blocking")
        options.add_argument("--lang=ru-RU")
        options.add_argument("--disable-blink-features=AutomationControlled")
        
        # User-Agent —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ Chrome
        ua = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
        options.add_argument(f"user-agent={ua}")
        
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
        options.set_capability("goog:loggingPrefs", {
            "performance": "ALL", 
            "browser": "ALL"
        })
        
        # –û—Ç–∫–ª—é—á–∞–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—é - –ë–ï–ó excludeSwitches –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        options.add_experimental_option('useAutomationExtension', False)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è PDF (–∏–∑ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤)
        prefs = {
            "download.default_directory": PDF_DIR,
            "download.prompt_for_download": False,
            "download.directory_upgrade": True,
            "safebrowsing.enabled": True,
            "plugins.always_open_pdf_externally": True,
        }
        options.add_experimental_option("prefs", prefs)
        
        try:
            self.driver = webdriver.Chrome(options=options)
            logger.info("‚úÖ Chrome –¥—Ä–∞–π–≤–µ—Ä —Å–æ–∑–¥–∞–Ω")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –¥—Ä–∞–π–≤–µ—Ä–∞: {e}")
            raise
        
        # –°–∫—Ä—ã–≤–∞–µ–º webdriver
        self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
        
        # –í–∫–ª—é—á–∞–µ–º CDP Network –¥–ª—è –ø–µ—Ä–µ—Ö–≤–∞—Ç–∞
        self.driver.execute_cdp_cmd("Network.enable", {})
        
        # –í–∫–ª—é—á–∞–µ–º Fetch –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø–µ—Ä–µ—Ö–≤–∞—Ç–∞ (–∏–∑ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤)
        self.driver.execute_cdp_cmd("Fetch.enable", {
            "patterns": [{"urlPattern": "*/Ras/Search*", "requestStage": "Response"}]
        })
        
        # –†–∞–∑—Ä–µ—à–∞–µ–º —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —á–µ—Ä–µ–∑ CDP (–∏–∑ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤)
        self.driver.execute_cdp_cmd("Page.setDownloadBehavior", {
            "behavior": "allow",
            "downloadPath": PDF_DIR
        })
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è –ù–ê–í–ò–ì–ê–¶–ò–ò (–≤–∞–∂–Ω–æ: –±–µ–∑ X-Requested-With, Accept –¥–ª—è HTML)
        self.driver.execute_cdp_cmd("Network.setExtraHTTPHeaders", {
            "headers": {
                "Accept-Language": "ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7",
                "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
                "Referer": "https://ras.arbitr.ru/"
            }
        })
        
        logger.info("‚úÖ CDP Network –≤–∫–ª—é—á–µ–Ω —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏")
        return self.driver
    
    def wait_ready(self, timeout=30):
        """–û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        try:
            WebDriverWait(self.driver, timeout).until(
                lambda d: d.execute_script("return document.readyState") == "complete"
            )
            time.sleep(0.5)
        except TimeoutException:
            logger.warning("‚ö†Ô∏è –¢–∞–π–º–∞—É—Ç –æ–∂–∏–¥–∞–Ω–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã")
    
    def humanize_behavior(self, moves=8):
        """–ò–º–∏—Ç–∞—Ü–∏—è —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è"""
        try:
            actions = ActionChains(self.driver)
            body = self.driver.find_element(By.TAG_NAME, "body")
            actions.move_to_element(body).perform()
            time.sleep(0.3)
            
            for _ in range(moves):
                actions.move_by_offset(
                    random.randint(-80, 120), 
                    random.randint(-60, 100)
                ).perform()
                time.sleep(random.uniform(0.15, 0.45))
            
            self.driver.execute_script("window.scrollBy(0, 400);")
            time.sleep(0.3)
            self.driver.execute_script("window.scrollBy(0, -200);")
            time.sleep(0.2)
        except Exception as e:
            logger.debug(f"–û—à–∏–±–∫–∞ humanize: {e}")
    
    def get_network_response(self, url_pattern="/Ras/Search", timeout=30):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –∏–∑ Network —á–µ—Ä–µ–∑ CDP - –û–°–ù–û–í–ù–û–ô –ú–ï–¢–û–î"""
        start_time = time.time()
        request_id = None
        
        logger.info(f"üîç –û–∂–∏–¥–∞–Ω–∏–µ XHR –∑–∞–ø—Ä–æ—Å–∞ –∫: {url_pattern}")
        
        while time.time() - start_time < timeout:
            try:
                # –ü–æ–ª—É—á–∞–µ–º –ª–æ–≥–∏ performance
                logs = self.driver.get_log('performance')
                
                for entry in logs:
                    try:
                        log = json.loads(entry['message'])['message']
                        
                        # –ò—â–µ–º responseReceived –¥–ª—è –Ω–∞—à–µ–≥–æ URL
                        if log['method'] == 'Network.responseReceived':
                            response = log['params']['response']
                            if url_pattern in response.get('url', ''):
                                request_id = log['params']['requestId']
                                status = response.get('status', 0)
                                logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω –æ—Ç–≤–µ—Ç: requestId={request_id}, status={status}")
                                
                                # –î–∞–µ–º –≤—Ä–µ–º—è –Ω–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏
                                time.sleep(1)
                                
                                # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–ª–æ –æ—Ç–≤–µ—Ç–∞
                                try:
                                    body_response = self.driver.execute_cdp_cmd(
                                        'Network.getResponseBody',
                                        {'requestId': request_id}
                                    )
                                    body = body_response.get('body', '')
                                    
                                    if body:
                                        logger.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ —Ç–µ–ª–æ –æ—Ç–≤–µ—Ç–∞: {len(body)} —Å–∏–º–≤–æ–ª–æ–≤")
                                        return {
                                            'status': status,
                                            'body': body,
                                            'url': response.get('url'),
                                            'requestId': request_id
                                        }
                                except Exception as e:
                                    logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–µ–ª–∞: {e}")
                                    continue
                    except (json.JSONDecodeError, KeyError, TypeError):
                        continue
                
                time.sleep(0.3)
                
            except Exception as e:
                logger.debug(f"–û—à–∏–±–∫–∞ –≤ —Ü–∏–∫–ª–µ –ø–µ—Ä–µ—Ö–≤–∞—Ç–∞: {e}")
                time.sleep(0.3)
        
        logger.warning(f"‚ö†Ô∏è –¢–∞–π–º–∞—É—Ç –æ–∂–∏–¥–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ ({timeout}s)")
        return None

    def wait_for_pdf_via_cdp(self, timeout: int = 30) -> Optional[Dict]:
        """–û–∂–∏–¥–∞–Ω–∏–µ –ø–µ—Ä–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ —Å URL, —Å–æ–¥–µ—Ä–∂–∞—â–∏–º /Document/Pdf/ —á–µ—Ä–µ–∑ CDP."""
        start_time = time.time()
        logger.info("üîç –û–∂–∏–¥–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ PDF (/Document/Pdf/)")
        while time.time() - start_time < timeout:
            try:
                logs = self.driver.get_log('performance')
                for entry in logs:
                    try:
                        log = json.loads(entry['message'])['message']
                        if log['method'] == 'Network.responseReceived':
                            response = log['params']['response']
                            url = response.get('url', '')
                            if '/Document/Pdf/' in url:
                                status = response.get('status', 0)
                                req_id = log['params']['requestId']
                                logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω PDF –æ—Ç–≤–µ—Ç: {status} {url}")
                                return { 'status': status, 'url': url, 'requestId': req_id }
                    except Exception:
                        continue
                time.sleep(0.2)
            except Exception:
                time.sleep(0.2)
        logger.warning("‚ö†Ô∏è PDF —á–µ—Ä–µ–∑ CDP –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω –∑–∞ –æ—Ç–≤–µ–¥–µ–Ω–Ω–æ–µ –≤—Ä–µ–º—è")
        return None
    
    def get_fetch_response(self, url_pattern="/Ras/Search", timeout=30):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ Fetch.enable - –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ô –ú–ï–¢–û–î"""
        start_time = time.time()
        
        logger.info(f"üîç –û–∂–∏–¥–∞–Ω–∏–µ Fetch –∑–∞–ø—Ä–æ—Å–∞ –∫: {url_pattern}")
        
        while time.time() - start_time < timeout:
            try:
                # –ü–æ–ª—É—á–∞–µ–º –ª–æ–≥–∏ performance –¥–ª—è Fetch
                logs = self.driver.get_log('performance')
                
                for entry in logs:
                    try:
                        log = json.loads(entry['message'])['message']
                        
                        # –ò—â–µ–º Fetch.requestPaused –¥–ª—è –Ω–∞—à–µ–≥–æ URL
                        if log['method'] == 'Fetch.requestPaused':
                            request = log['params']['request']
                            if url_pattern in request.get('url', ''):
                                request_id = log['params']['requestId']
                                logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω Fetch –∑–∞–ø—Ä–æ—Å: requestId={request_id}")
                                
                                # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –∑–∞–ø—Ä–æ—Å
                                self.driver.execute_cdp_cmd('Fetch.continueRequest', {
                                    'requestId': request_id
                                })
                                
                                # –ñ–¥–µ–º –æ—Ç–≤–µ—Ç
                                time.sleep(1)
                                
                                # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–ª–æ –æ—Ç–≤–µ—Ç–∞
                                try:
                                    body_response = self.driver.execute_cdp_cmd(
                                        'Fetch.getResponseBody',
                                        {'requestId': request_id}
                                    )
                                    body = body_response.get('body', '')
                                    
                                    if body:
                                        logger.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ —Ç–µ–ª–æ Fetch –æ—Ç–≤–µ—Ç–∞: {len(body)} —Å–∏–º–≤–æ–ª–æ–≤")
                                        return {
                                            'status': 200,  # Fetch –Ω–µ –≤—Å–µ–≥–¥–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç—É—Å
                                            'body': body,
                                            'url': request.get('url'),
                                            'requestId': request_id
                                        }
                                except Exception as e:
                                    logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è Fetch —Ç–µ–ª–∞: {e}")
                                    continue
                    except (json.JSONDecodeError, KeyError, TypeError):
                        continue
                
                time.sleep(0.3)
                
            except Exception as e:
                logger.debug(f"–û—à–∏–±–∫–∞ –≤ —Ü–∏–∫–ª–µ Fetch –ø–µ—Ä–µ—Ö–≤–∞—Ç–∞: {e}")
                time.sleep(0.3)
        
        logger.warning(f"‚ö†Ô∏è –¢–∞–π–º–∞—É—Ç –æ–∂–∏–¥–∞–Ω–∏—è Fetch –æ—Ç–≤–µ—Ç–∞ ({timeout}s)")
        return None
    
    def setup_xhr_interceptor(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ JS –ø–µ—Ä–µ—Ö–≤–∞—Ç—á–∏–∫–∞ XHR (–∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç)"""
        intercept_script = """
        (function() {
            if (window._rasInterceptorInstalled) return;
            window._rasInterceptorInstalled = true;
            
            window._rasResponses = [];
            window._rasLastResponse = null;

            const originalXHR = window.XMLHttpRequest;
            window.XMLHttpRequest = function() {
                const xhr = new originalXHR();
                const originalOpen = xhr.open;
                const originalSend = xhr.send;

                xhr.open = function(method, url, ...args) {
                    this._method = method;
                    this._url = url;
                    return originalOpen.apply(this, [method, url, ...args]);
                };

                xhr.send = function(data) {
                    this._data = data;
                    const originalOnReadyStateChange = this.onreadystatechange;

                    this.onreadystatechange = function() {
                        if (this.readyState === 4) {
                            if (this._url && this._url.includes('Ras/Search')) {
                                const resp = {
                                    transport: 'xhr',
                                    url: this._url,
                                    status: this.status,
                                    responseText: this.responseText,
                                    method: this._method,
                                    data: this._data,
                                    ts: Date.now()
                                };
                                window._rasResponses.push(resp);
                                window._rasLastResponse = resp;
                                console.log('[RAS] XHR –ø–µ—Ä–µ—Ö–≤–∞—á–µ–Ω:', this._url, this.status);
                            }
                        }
                        if (originalOnReadyStateChange) {
                            originalOnReadyStateChange.apply(this, arguments);
                        }
                    };

                    return originalSend.apply(this, [data]);
                };

                return xhr;
            };

            // –ü–µ—Ä–µ—Ö–≤–∞—Ç Fetch API
            const originalFetch = window.fetch;
            window.fetch = function(...args) {
                return originalFetch.apply(this, args).then(response => {
                    const url = args[0];
                    if (url && url.includes('Ras/Search')) {
                        response.clone().text().then(text => {
                            const resp = {
                                transport: 'fetch',
                                url: url,
                                status: response.status,
                                responseText: text,
                                ts: Date.now()
                            };
                            window._rasResponses.push(resp);
                            window._rasLastResponse = resp;
                            console.log('[RAS] Fetch –ø–µ—Ä–µ—Ö–≤–∞—á–µ–Ω:', url, response.status);
                        });
                    }
                    return response;
                });
            };

            window._rasClear = function() {
                window._rasResponses = [];
                window._rasLastResponse = null;
            };
            
            console.log('[RAS] –ü–µ—Ä–µ—Ö–≤–∞—Ç—á–∏–∫ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω');
        })();
        """
        
        try:
            self.driver.execute_script(intercept_script)
            logger.info("‚úÖ JS XHR –ø–µ—Ä–µ—Ö–≤–∞—Ç—á–∏–∫ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω (–∑–∞–ø–∞—Å–Ω–æ–π)")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å JS –ø–µ—Ä–µ—Ö–≤–∞—Ç—á–∏–∫: {e}")

    def get_xhr_response(self, timeout=30):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ XHR –æ—Ç–≤–µ—Ç–∞ –∏–∑ JS –ø–µ—Ä–µ—Ö–≤–∞—Ç—á–∏–∫–∞ (–∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç)"""
        start_time = time.time()
        while time.time() - start_time < timeout:
            try:
                responses = self.driver.execute_script("return window._rasResponses || [];")
                if responses and isinstance(responses, list):
                    filtered = [r for r in responses if r and 'Ras/Search' in (r.get('url') or '')]
                    if filtered:
                        resp = max(filtered, key=lambda r: r.get('ts', 0))
                        logger.info(f"‚úÖ JS –ø–µ—Ä–µ—Ö–≤–∞—Ç—á–∏–∫: status={resp.get('status')}")
                        return {
                            'status': resp.get('status'),
                            'body': resp.get('responseText', ''),
                            'url': resp.get('url')
                        }
                time.sleep(0.5)
            except Exception as e:
                logger.debug(f"–û–∂–∏–¥–∞–Ω–∏–µ JS –æ—Ç–≤–µ—Ç–∞: {e}")
                time.sleep(0.5)
        logger.warning("‚ö†Ô∏è JS –ø–µ—Ä–µ—Ö–≤–∞—Ç—á–∏–∫: –æ—Ç–≤–µ—Ç –Ω–µ –ø–æ–ª—É—á–µ–Ω")
        return None
    
    def clear_intercept_buffer(self):
        """–û—á–∏—Å—Ç–∫–∞ –±—É—Ñ–µ—Ä–∞ –ø–µ—Ä–µ—Ö–≤–∞—Ç–∞"""
        try:
            self.driver.execute_script("if (window._rasClear) window._rasClear();")
        except:
            pass
    
    def wait_download_finished(self, directory: str, timeout: int = 240):
        """–û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è PDF (–∏–∑ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤)"""
        import glob
        start = time.time()
        last_size = None
        stable_ticks = 0
        
        while time.time() - start < timeout:
            # –ò–¥—ë—Ç –∑–∞–≥—Ä—É–∑–∫–∞, –µ—Å–ª–∏ –µ—â—ë –µ—Å—Ç—å .crdownload
            crs = glob.glob(os.path.join(directory, "*.crdownload"))
            if crs:
                # –ö–æ–Ω—Ç—Ä–æ–ª—å "–Ω–µ –∑–∞–ª–∏–ø–ª–æ –ª–∏": –ø—Ä–æ–≤–µ—Ä—è–µ–º, –º–µ–Ω—è–µ—Ç—Å—è –ª–∏ —Ä–∞–∑–º–µ—Ä —Å–∞–º–æ–≥–æ –±–æ–ª—å—à–æ–≥–æ .crdownload
                largest = max(crs, key=lambda p: os.path.getsize(p))
                size = os.path.getsize(largest)
                if last_size == size:
                    stable_ticks += 1
                else:
                    stable_ticks = 0
                last_size = size
                # –ï—Å–ª–∏ —Ä–∞–∑–º–µ—Ä —Å—Ç–∞–±–∏–ª–µ–Ω —Å–ª–∏—à–∫–æ–º –¥–æ–ª–≥–æ ‚Äî –≤–µ—Ä–æ—è—Ç–Ω–æ –∑–∞–≤–∏—Å–ª–æ
                if stable_ticks > 60:  # ~30 —Å–µ–∫ –ø—Ä–∏ —à–∞–≥–µ 0.5
                    break
                time.sleep(0.5)
                continue
            
            # –ù–µ—Ç .crdownload ‚Äî –∏—â–µ–º —Å–≤–µ–∂–∏–π PDF
            pdfs = [p for p in Path(directory).glob("*.pdf") if p.stat().st_mtime >= start - 2]
            if pdfs:
                latest = max(pdfs, key=lambda p: p.stat().st_mtime)
                logger.info(f"‚úÖ PDF —Å–∫–∞—á–∞–Ω: {latest}")
                return str(latest)
            time.sleep(0.5)
        
        raise TimeoutError("PDF –Ω–µ —Å–∫–∞—á–∞–ª—Å—è –≤–æ–≤—Ä–µ–º—è –∏–ª–∏ –∑–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–∏—Å–ª–∞")


class CurlCffiClient:
    """–ö–ª–∏–µ–Ω—Ç —Å curl_cffi impersonation –¥–ª—è –≤–Ω–µ—à–Ω–∏—Ö POST (–∑–∞–ø–∞—Å–Ω–æ–π –º–µ—Ç–æ–¥)"""
    
    def __init__(self):
        self.session = None
        self.cookies = {}
        
    def setup_session(self, cookies_from_selenium=None):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å–µ—Å—Å–∏–∏ —Å impersonation"""
        if not CURL_CFFI_AVAILABLE:
            logger.error("‚ùå curl_cffi –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            return False
            
        try:
            # –°–æ–∑–¥–∞—ë–º —Å–µ—Å—Å–∏—é —Å impersonation Chrome
            self.session = curl_requests.Session()
            
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –∏–º–∏—Ç–∞—Ü–∏–∏ –±—Ä–∞—É–∑–µ—Ä–∞
            self.session.headers.update({
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
                "Accept": "application/json, text/javascript, */*; q=0.01",
                "Accept-Language": "ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7",
                "Referer": "https://ras.arbitr.ru/",
                "X-Requested-With": "XMLHttpRequest",
                "Origin": "https://ras.arbitr.ru"
            })
            
            # –ü–µ—Ä–µ–Ω–æ—Å–∏–º –∫—É–∫–∏ –∏–∑ Selenium –µ—Å–ª–∏ –µ—Å—Ç—å
            if cookies_from_selenium:
                for cookie in cookies_from_selenium:
                    self.session.cookies.set(
                        cookie['name'], 
                        cookie['value'],
                        domain=cookie.get('domain'),
                        path=cookie.get('path', '/')
                    )
                logger.info(f"‚úÖ –ü–µ—Ä–µ–Ω–µ—Å–µ–Ω–æ {len(cookies_from_selenium)} –∫—É–∫–∏ –∏–∑ Selenium")
            
            logger.info("‚úÖ curl_cffi —Å–µ—Å—Å–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞ —Å impersonation")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ curl_cffi: {e}")
            return False
    
    def post_search(self, payload: dict, timeout: int = 30):
        """POST –∑–∞–ø—Ä–æ—Å –∫ /Ras/Search —á–µ—Ä–µ–∑ curl_cffi"""
        if not self.session:
            logger.error("‚ùå –°–µ—Å—Å–∏—è –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞")
            return None
            
        try:
            logger.info("üîç –û—Ç–ø—Ä–∞–≤–∫–∞ POST —á–µ—Ä–µ–∑ curl_cffi...")
            
            response = self.session.post(
                SEARCH_URL,
                json=payload,
                timeout=timeout,
                impersonate="chrome131",  # –ò–º–∏—Ç–∞—Ü–∏—è Chrome 131
                verify=False  # –û—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É SSL
            )
            
            logger.info(f"‚úÖ curl_cffi –æ—Ç–≤–µ—Ç: {response.status_code}")
            
            if response.status_code == 200:
                try:
                    data = response.json()
                    return {
                        'status': response.status_code,
                        'body': json.dumps(data),
                        'url': SEARCH_URL,
                        'method': 'curl_cffi'
                    }
                except json.JSONDecodeError:
                    logger.error("‚ùå curl_cffi: –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π JSON")
                    return None
            else:
                logger.error(f"‚ùå curl_cffi: HTTP {response.status_code}")
                return None
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ curl_cffi POST: {e}")
            return None


class RasSearchHandler:
    """–ö–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ñ–æ—Ä–º–æ–π –ø–æ–∏—Å–∫–∞ - –ü–û–õ–ù–û–°–¢–¨–Æ –ü–ï–†–ï–†–ê–ë–û–¢–ê–ù –î–õ–Ø SPA"""
    
    def __init__(self, parser: RasArbitrParser):
        self.parser = parser
        self.driver = parser.driver
    
    def wait_for_spa_ready(self, timeout=30):
        """–û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ SPA –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
        try:
            logger.info("‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ SPA –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è...")
            start = time.time()
            
            while time.time() - start < timeout:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Ñ–æ—Ä–º—ã
                inputs = self.driver.find_elements(By.CSS_SELECTOR, "input[type='text'], input:not([type='hidden'])")
                buttons = self.driver.find_elements(By.CSS_SELECTOR, "button, input[type='submit']")
                
                visible_inputs = [i for i in inputs if i.is_displayed()]
                visible_buttons = [b for b in buttons if b.is_displayed()]
                
                if len(visible_inputs) >= 2 and len(visible_buttons) >= 1:
                    logger.info(f"‚úÖ SPA –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {len(visible_inputs)} –ø–æ–ª–µ–π, {len(visible_buttons)} –∫–Ω–æ–ø–æ–∫")
                    return True
                
                time.sleep(0.5)
            
            logger.warning("‚ö†Ô∏è –¢–∞–π–º–∞—É—Ç –æ–∂–∏–¥–∞–Ω–∏—è SPA")
            return False
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–∂–∏–¥–∞–Ω–∏—è SPA: {e}")
            return False
        
    def close_overlay(self, max_attempts=3):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ –ø—Ä–æ–º–æ-–æ–≤–µ—Ä–ª–µ—è"""
        try:
            logger.info("üîç –ü–æ–∏—Å–∫ –æ–≤–µ—Ä–ª–µ–µ–≤...")
            
            # –°–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –∑–∞–∫—Ä—ã—Ç–∏—è –æ–≤–µ—Ä–ª–µ–µ–≤
            close_selectors = [
                "button[aria-label='Close']",
                "button[data-dismiss='modal']",
                ".modal .close",
                ".popup .close",
                ".overlay .close",
                "[class*='close-button']",
                "[class*='modal'] button",
                "div[class*='overlay'] button",
                "div[class*='popup'] button"
            ]
            
            closed = False
            for attempt in range(max_attempts):
                for selector in close_selectors:
                    try:
                        elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                        for element in elements:
                            if element.is_displayed():
                                # –ü—Ä–æ–±—É–µ–º –∫–ª–∏–∫–Ω—É—Ç—å
                                try:
                                    element.click()
                                except:
                                    self.driver.execute_script("arguments[0].click();", element)
                                
                                logger.info(f"‚úÖ –û–≤–µ—Ä–ª–µ–π –∑–∞–∫—Ä—ã—Ç: {selector}")
                                time.sleep(0.5)
                                closed = True
                                break
                    except Exception as e:
                        continue
                
                if closed:
                    break
                    
                # –ü—Ä–æ–±—É–µ–º ESC
                try:
                    body = self.driver.find_element(By.TAG_NAME, "body")
                    body.send_keys(Keys.ESCAPE)
                    time.sleep(0.5)
                    logger.info("‚úÖ ESC –Ω–∞–∂–∞—Ç")
                except:
                    pass
                
                time.sleep(0.5)
            
            if not closed:
                logger.info("‚ÑπÔ∏è –û–≤–µ—Ä–ª–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ —É–∂–µ –∑–∞–∫—Ä—ã—Ç")
                    
        except Exception as e:
            logger.debug(f"–û—à–∏–±–∫–∞ –∑–∞–∫—Ä—ã—Ç–∏—è –æ–≤–µ—Ä–ª–µ—è: {e}")
    
    def fill_date_field(self, selectors: List[str], date_value: str, field_name: str) -> bool:
        """–ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–æ–ª—è –¥–∞—Ç—ã"""
        for selector in selectors:
            try:
                # –ñ–¥–µ–º –ø–æ—è–≤–ª–µ–Ω–∏—è —ç–ª–µ–º–µ–Ω—Ç–∞
                element = WebDriverWait(self.driver, 5).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, selector))
                )
                
                # –ü—Ä–æ–∫—Ä—É—á–∏–≤–∞–µ–º –∫ —ç–ª–µ–º–µ–Ω—Ç—É
                self.driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", element)
                time.sleep(0.3)
                
                # –û—á–∏—â–∞–µ–º –∏ –∑–∞–ø–æ–ª–Ω—è–µ–º
                element.clear()
                time.sleep(0.2)
                element.send_keys(date_value)
                time.sleep(0.3)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∑–Ω–∞—á–µ–Ω–∏–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ
                current_value = element.get_attribute('value')
                if current_value and date_value in current_value:
                    logger.info(f"‚úÖ –ü–æ–ª–µ '{field_name}' –∑–∞–ø–æ–ª–Ω–µ–Ω–æ: {date_value} (—Å–µ–ª–µ–∫—Ç–æ—Ä: {selector})")
                    return True
                    
            except Exception as e:
                logger.debug(f"–°–µ–ª–µ–∫—Ç–æ—Ä {selector} –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e}")
                continue
        
        return False
    
    def fill_search_form(self, date_from: str, date_to: str):
        """–ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ —Ñ–æ—Ä–º—ã –ø–æ–∏—Å–∫–∞ - –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø"""
        try:
            logger.info(f"üìù –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ —Ñ–æ—Ä–º—ã: {date_from} - {date_to}")
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –¥–∞—Ç—ã –≤ —Ñ–æ—Ä–º–∞—Ç –î–î.–ú–ú.–ì–ì–ì–ì
            date_from_ui = datetime.strptime(date_from, "%Y-%m-%d").strftime("%d.%m.%Y")
            date_to_ui = datetime.strptime(date_to, "%Y-%m-%d").strftime("%d.%m.%Y")

            # –ó–∞–∫—Ä—ã–≤–∞–µ–º –æ–≤–µ—Ä–ª–µ–∏
            self.close_overlay()
            time.sleep(2)
            
            # –î–∞—ë–º —Å—Ç—Ä–∞–Ω–∏—Ü–µ –∑–∞–≥—Ä—É–∑–∏—Ç—å—Å—è –ø–æ–ª–Ω–æ—Å—Ç—å—é (SPA –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ)
            logger.info("‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ SPA...")
            time.sleep(3)
            
            # –ü–†–ê–í–ò–õ–¨–ù–´–ï —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –∏–∑ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            date_from_selectors = [
                "#sug-dates label.from input.anyway_position_top",  # –û–°–ù–û–í–ù–û–ô –∏–∑ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
                "#sug-dates label.from input",
                "input[name='DateFrom']",
                "#DateFrom",
                "input[id*='DateFrom']",
                "input[placeholder*='01.01']",
                "input[placeholder*='–¥–∞—Ç–∞']",
                ".date-from input",
                ".from input",
                "label.from input",
                "input[type='text'][name*='from']",
                "input[type='text'][name*='From']",
                ".b-date-range input:first-of-type",
                ".date-range input:first-of-type"
            ]
            
            date_to_selectors = [
                "#sug-dates label.to input.anyway_position_top",  # –û–°–ù–û–í–ù–û–ô –∏–∑ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
                "#sug-dates label.to input",
                "input[name='DateTo']",
                "#DateTo",
                "input[id*='DateTo']",
                ".date-to input",
                ".to input",
                "label.to input",
                "input[type='text'][name*='to']",
                "input[type='text'][name*='To']",
                ".b-date-range input:last-of-type",
                ".date-range input:last-of-type",
                "input[placeholder*='31.12']"
            ]
            
            # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –ª—é–±–æ–µ input –ø–æ–ª–µ –¥–ª—è –¥–∞—Ç
            logger.info("üîç –ü–æ–∏—Å–∫ –ø–æ–ª–µ–π –≤–≤–æ–¥–∞ –¥–∞—Ç...")
            all_inputs = self.driver.find_elements(By.CSS_SELECTOR, "input[type='text'], input:not([type])")
            logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(all_inputs)} —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –ø–æ–ª–µ–π")
            
            # –ó–∞–ø–æ–ª–Ω—è–µ–º –¥–∞—Ç—É "–æ—Ç"
            from_filled = self.fill_date_field(date_from_selectors, date_from_ui, "–î–∞—Ç–∞ –æ—Ç")
            
            # –ó–∞–ø–æ–ª–Ω—è–µ–º –¥–∞—Ç—É "–¥–æ"
            to_filled = self.fill_date_field(date_to_selectors, date_to_ui, "–î–∞—Ç–∞ –¥–æ")
            
            if not from_filled or not to_filled:
                logger.warning("‚ö†Ô∏è –ù–µ –≤—Å–µ –ø–æ–ª—è –¥–∞—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω—ã —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–º–∏ —Å–µ–ª–µ–∫—Ç–æ—Ä–∞–º–∏")
                logger.info("üîß –ü—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ - –ø–æ –ø–æ—Ä—è–¥–∫—É –ø–æ–ª–µ–π...")
                
                # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞: –∑–∞–ø–æ–ª–Ω—è–µ–º –ø–µ—Ä–≤—ã–µ –¥–≤–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –ø–æ–ª—è
                try:
                    date_inputs = [inp for inp in all_inputs if inp.is_displayed() and inp.is_enabled()]
                    if len(date_inputs) >= 2:
                        # –ü–µ—Ä–≤–æ–µ –ø–æ–ª–µ = –¥–∞—Ç–∞ –æ—Ç
                        date_inputs[0].clear()
                        date_inputs[0].send_keys(date_from_ui)
                        logger.info(f"‚úÖ –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞: –ø–æ–ª–µ 1 –∑–∞–ø–æ–ª–Ω–µ–Ω–æ {date_from_ui}")
                        time.sleep(0.5)
                        
                        # –í—Ç–æ—Ä–æ–µ –ø–æ–ª–µ = –¥–∞—Ç–∞ –¥–æ
                        date_inputs[1].clear()
                        date_inputs[1].send_keys(date_to_ui)
                        logger.info(f"‚úÖ –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞: –ø–æ–ª–µ 2 –∑–∞–ø–æ–ª–Ω–µ–Ω–æ {date_to_ui}")
                        
                        from_filled = True
                        to_filled = True
                except Exception as e:
                    logger.error(f"‚ùå –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e}")
            
            if not from_filled or not to_filled:
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º HTML –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
                with open(os.path.join(SAVE_DIR, "form_debug.html"), "w", encoding="utf-8") as f:
                    f.write(self.driver.page_source)
                logger.error("üíæ HTML —Ñ–æ—Ä–º—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ form_debug.html")
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–∫—Ä–∏–Ω—à–æ—Ç
                try:
                    screenshot_path = os.path.join(SAVE_DIR, "form_debug_screenshot.png")
                    self.driver.save_screenshot(screenshot_path)
                    logger.info(f"üì∏ –°–∫—Ä–∏–Ω—à–æ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {screenshot_path}")
                except:
                    pass
                
                return False
            
            time.sleep(1)
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è —Ñ–æ—Ä–º—ã: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return False
    
    def submit_search(self):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ —Ñ–æ—Ä–º—ã –ø–æ–∏—Å–∫–∞ (—Ä–æ–±–∞—Å—Ç–Ω–∞—è)"""
        try:
            logger.info("üöÄ –û—Ç–ø—Ä–∞–≤–∫–∞ —Ñ–æ—Ä–º—ã –ø–æ–∏—Å–∫–∞...")
            
            # –°–µ–ª–µ–∫—Ç–æ—Ä—ã –∫–Ω–æ–ø–∫–∏ –æ—Ç–ø—Ä–∞–≤–∫–∏
            submit_selectors = [
                "#b-form-submit button[type='submit']",
                "button[type='submit']",
                "input[type='submit']",
                ".search-button",
                "button[class*='submit']",
                "[data-action='search']"
            ]
            
            submitted = False
            
            # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –∏ –∫–ª–∏–∫–Ω—É—Ç—å –∫–Ω–æ–ø–∫—É
            for selector in submit_selectors:
                try:
                    button = self.driver.find_element(By.CSS_SELECTOR, selector)
                    if button.is_displayed() and button.is_enabled():
                        # –ü—Ä–æ–∫—Ä—É—á–∏–≤–∞–µ–º –∫ –∫–Ω–æ–ø–∫–µ
                        self.driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", button)
                        time.sleep(0.5)
                        
                        # –ü—Ä–æ–±—É–µ–º –æ–±—ã—á–Ω—ã–π –∫–ª–∏–∫
                        try:
                            button.click()
                            submitted = True
                            logger.info(f"‚úÖ –§–æ—Ä–º–∞ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞ (–∫–ª–∏–∫): {selector}")
                        except Exception as e:
                            # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å - —á–µ—Ä–µ–∑ JS
                            self.driver.execute_script("arguments[0].click();", button)
                            submitted = True
                            logger.info(f"‚úÖ –§–æ—Ä–º–∞ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞ (JS): {selector}")
                        
                        if submitted:
                            break
                            
                except Exception as e:
                    logger.debug(f"–°–µ–ª–µ–∫—Ç–æ—Ä {selector} –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e}")
                    continue
            
            # –ï—Å–ª–∏ –∫–Ω–æ–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ - –ø—Ä–æ–±—É–µ–º –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Ñ–æ—Ä–º—É –Ω–∞–ø—Ä—è–º—É—é
            if not submitted:
                logger.warning("‚ö†Ô∏è –ö–Ω–æ–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –æ—Ç–ø—Ä–∞–≤–∫–∞ —á–µ—Ä–µ–∑ form.submit()")
                result = self.driver.execute_script("""
                    const form = document.querySelector('form');
                    if (form) {
                        if (form.requestSubmit) {
                            form.requestSubmit();
                        } else {
                            form.submit();
                        }
                        return true;
                    }
                    return false;
                """)
                
                if result:
                    submitted = True
                    logger.info("‚úÖ –§–æ—Ä–º–∞ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞ —á–µ—Ä–µ–∑ form.submit()")
            
            if submitted:
                time.sleep(2)  # –î–∞–µ–º –≤—Ä–µ–º—è –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É
                return True
            else:
                logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Ñ–æ—Ä–º—É")
                return False
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Ñ–æ—Ä–º—ã: {e}")
            return False


class RasArbitrScraper:
    """–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å CDP –ø–µ—Ä–µ—Ö–≤–∞—Ç–æ–º"""
    
    def __init__(self):
        self.parser = None
        self.search_handler = None
        self.results = []
        self.session_stats = {
            'success': 0,
            'failed': 0,
            'total_requests': 0
        }
    
    def prewarm_session(self):
        """–ü—Ä–æ–≥—Ä–µ–≤ —Å–µ—Å—Å–∏–∏"""
        try:
            logger.info("üî• –ü—Ä–æ–≥—Ä–µ–≤ —Å–µ—Å—Å–∏–∏...")
            self.parser.driver.get(RAS_HOME)
            self.parser.wait_ready()
            self.parser.humanize_behavior(moves=random.randint(6, 12))
            time.sleep(random.uniform(1.5, 3.0))
            logger.info("‚úÖ –°–µ—Å—Å–∏—è –ø—Ä–æ–≥—Ä–µ—Ç–∞")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≥—Ä–µ–≤–∞ —Å–µ—Å—Å–∏–∏: {e}")
    
    def search_by_date_range(self, date_from: str, date_to: str, use_cdp=True, use_js=True) -> Optional[Dict]:
        """–ü–æ–∏—Å–∫ –ø–æ –¥–∏–∞–ø–∞–∑–æ–Ω—É –¥–∞—Ç —Å –ø–µ—Ä–µ—Ö–≤–∞—Ç–æ–º –æ—Ç–≤–µ—Ç–∞ - –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø"""
        try:
            logger.info(f"üîç –ü–æ–∏—Å–∫: {date_from} - {date_to}")
            
            # –ù–∞–¥–µ–∂–Ω–∞—è –Ω–∞–≤–∏–≥–∞—Ü–∏—è –≤ SPA: —Å–Ω–∞—á–∞–ª–∞ –≥–ª–∞–≤–Ω–∞—è, –∑–∞—Ç–µ–º hash, –∑–∞—Ç–µ–º –ø—Ä–æ–≤–µ—Ä–∫–∞ —ç–ª–µ–º–µ–Ω—Ç–æ–≤
            logger.info(f"üìÑ –û—Ç–∫—Ä—ã–≤–∞–µ–º –≥–ª–∞–≤–Ω—É—é: {RAS_HOME}")
            self.parser.driver.get(RAS_HOME)
            self.parser.wait_ready()
            time.sleep(1.5)
            
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –Ω—É–∂–Ω—ã–π hash –∏ –∏–Ω–∏—Ü–∏–∏—Ä—É–µ–º —Å–æ–±—ã—Ç–∏–µ
            try:
                self.parser.driver.execute_script("window.location.hash='searchPrintForm'; window.dispatchEvent(new HashChangeEvent('hashchange'));")
            except Exception:
                pass
            
            # –§–æ–ª–±—ç–∫: –ø—Ä—è–º–æ–π URL —Å hash, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            try:
                WebDriverWait(self.parser.driver, 10).until(
                    lambda d: 'searchPrintForm' in d.execute_script('return window.location.hash || \"\";')
                )
            except Exception:
                logger.info(f"‚Ü©Ô∏è –§–æ–ª–±—ç–∫ –Ω–∞ –ø—Ä—è–º–æ–π URL: {RAS_SEARCH_PAGE}")
                self.parser.driver.get(RAS_SEARCH_PAGE)
                self.parser.wait_ready()
            
            # –ñ–¥–µ–º –ø–æ—è–≤–ª–µ–Ω–∏—è –∫–ª—é—á–µ–≤—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Ñ–æ—Ä–º—ã (–¥–æ 30 —Å–µ–∫)
            try:
                form_ready_selectors = [
                    "#sug-dates",
                    "#b-form-submit button[type='submit']",
                    "#sug-dates label.from input",
                    "input[name='DateFrom']",
                ]
                end_time = time.time() + 30
                ready = False
                while time.time() < end_time and not ready:
                    for sel in form_ready_selectors:
                        try:
                            el = self.parser.driver.find_element(By.CSS_SELECTOR, sel)
                            if el and el.is_displayed():
                                ready = True
                                break
                        except Exception:
                            continue
                    if not ready:
                        time.sleep(0.5)
                if not ready:
                    logger.warning("‚ö†Ô∏è –§–æ—Ä–º–∞ –ø–æ–∏—Å–∫–∞ –Ω–µ –≤–∏–¥–Ω–∞ –ø–æ—Å–ª–µ 30—Å –æ–∂–∏–¥–∞–Ω–∏—è")
            except Exception:
                pass
            
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–µ—Ä–µ—Ö–≤–∞—Ç—á–∏–∫–∏
            if use_js:
                self.parser.setup_xhr_interceptor()
            
            # –°–æ–∑–¥–∞—ë–º handler –∏ –∂–¥—ë–º –∑–∞–≥—Ä—É–∑–∫–∏ SPA
            self.search_handler = RasSearchHandler(self.parser)
            
            # –ñ–¥—ë–º –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ SPA
            if not self.search_handler.wait_for_spa_ready(timeout=30):
                logger.error("‚ùå SPA –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª–æ—Å—å")
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
                with open(os.path.join(SAVE_DIR, "spa_not_ready.html"), "w", encoding="utf-8") as f:
                    f.write(self.parser.driver.page_source)
                return None
            
            # –ó–∞–ø–æ–ª–Ω—è–µ–º —Ñ–æ—Ä–º—É
            if not self.search_handler.fill_search_form(date_from, date_to):
                logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–æ–ª–Ω–∏—Ç—å —Ñ–æ—Ä–º—É")
                return None
            
            # –û—á–∏—â–∞–µ–º –±—É—Ñ–µ—Ä—ã –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π
            self.parser.clear_intercept_buffer()
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–æ—Ä–º—É
            if not self.search_handler.submit_search():
                logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Ñ–æ—Ä–º—É")
                return None
            
            # –ñ–¥–µ–º –æ—Ç–≤–µ—Ç
            time.sleep(2)
            
            # –¢–æ–ª—å–∫–æ CDP Network (–≤–Ω—É—Ç—Ä–∏ –±—Ä–∞—É–∑–µ—Ä–∞)
            logger.info("üîç –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç —á–µ—Ä–µ–∑ CDP Network...")
            response = self.parser.get_network_response(url_pattern="/Ras/Search", timeout=20)
            
            if not response:
                logger.error("‚ùå –û—Ç–≤–µ—Ç –Ω–µ –ø–æ–ª—É—á–µ–Ω")
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
                with open(os.path.join(SAVE_DIR, "search_debug.html"), "w", encoding="utf-8") as f:
                    f.write(self.parser.driver.page_source)
                logger.info("üíæ HTML —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ search_debug.html")
                return None
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å
            status = response.get('status', 0)
            if status != 200:
                logger.error(f"‚ùå HTTP –æ—à–∏–±–∫–∞: {status}")
                return None
            
            # –ü–∞—Ä—Å–∏–º JSON
            try:
                body = response.get('body', '{}')
                if not body or body == '{}':
                    logger.error("‚ùå –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç")
                    return None
                
                data = json.loads(body)
                
                if not data or not isinstance(data, dict):
                    logger.error("‚ùå –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π JSON")
                    return None
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö
                records = data.get('Data', [])
                total = data.get('Total', 0)
                
                logger.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ: {len(records)} –∑–∞–ø–∏—Å–µ–π –∏–∑ {total}")
                
                return {
                    'data': data,
                    'date_from': date_from,
                    'date_to': date_to,
                    'timestamp': datetime.now().isoformat(),
                    'records_count': len(records),
                    'total': total
                }
                
            except json.JSONDecodeError as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—ã–π –æ—Ç–≤–µ—Ç
                with open(os.path.join(SAVE_DIR, "response_error.txt"), "w", encoding="utf-8") as f:
                    f.write(body[:5000])
                return None
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return None
    
    def scrape_date_range(self, date_from: str, date_to: str, max_retries=3) -> List[Dict]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ –¥–∞—Ç —Å retry"""
        try:
            logger.info(f"\n{'='*60}")
            logger.info(f"üöÄ –ó–ê–ü–£–°–ö –ü–ê–†–°–ò–ù–ì–ê: {date_from} - {date_to}")
            logger.info(f"{'='*60}\n")
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞—Ç
            try:
                datetime.strptime(date_from, "%Y-%m-%d")
                datetime.strptime(date_to, "%Y-%m-%d")
            except ValueError as e:
                logger.error(f"‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã: {e}")
                return []
            
            # –°–æ–∑–¥–∞–µ–º –¥—Ä–∞–π–≤–µ—Ä
            self.parser = RasArbitrParser()
            self.parser.build_driver()
            
            # –ü—Ä–æ–≥—Ä–µ–≤
            self.prewarm_session()
            
            all_results = []
            
            # –ü–æ–ø—ã—Ç–∫–∏ —Å retry
            for attempt in range(1, max_retries + 1):
                logger.info(f"\nüìç –ü–æ–ø—ã—Ç–∫–∞ {attempt}/{max_retries}")
                
                result = self.search_by_date_range(date_from, date_to)
                
                if result:
                    all_results.append(result)
                    self.session_stats['success'] += 1
                    logger.info(f"‚úÖ –ü–æ–ø—ã—Ç–∫–∞ {attempt} —É—Å–ø–µ—à–Ω–∞")
                    break
                else:
                    self.session_stats['failed'] += 1
                    logger.warning(f"‚ö†Ô∏è –ü–æ–ø—ã—Ç–∫–∞ {attempt} –Ω–µ —É–¥–∞–ª–∞—Å—å")
                    
                    if attempt < max_retries:
                        # –ü—Ä–æ–≥—Ä–µ–≤ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–æ–º
                        backoff = 10 * (2 ** (attempt - 1))
                        logger.info(f"‚è≥ –ü–∞—É–∑–∞ {backoff}s –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–æ–º...")
                        time.sleep(backoff)
                        self.prewarm_session()
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            if all_results:
                self.save_results(all_results, date_from, date_to)
            
            logger.info(f"\n{'='*60}")
            logger.info(f"üìä –ò–¢–û–ì–û: –£—Å–ø–µ—à–Ω–æ={self.session_stats['success']}, –û—à–∏–±–æ–∫={self.session_stats['failed']}")
            logger.info(f"{'='*60}\n")
            
            return all_results
            
        except Exception as e:
            logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return []
        finally:
            # –ó–∞–∫—Ä—ã–≤–∞–µ–º –±—Ä–∞—É–∑–µ—Ä
            if self.parser and self.parser.driver:
                try:
                    logger.info("üîí –ó–∞–∫—Ä—ã—Ç–∏–µ –±—Ä–∞—É–∑–µ—Ä–∞...")
                    # –û—Å—Ç–∞–≤–ª—è–µ–º –±—Ä–∞—É–∑–µ—Ä –æ—Ç–∫—Ä—ã—Ç—ã–º –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                    input("\n‚è∏Ô∏è  –ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –∑–∞–∫—Ä—ã—Ç–∏—è –±—Ä–∞—É–∑–µ—Ä–∞...")
                    self.parser.driver.quit()
                except:
                    pass
    
    def save_results(self, results: List[Dict], date_from: str, date_to: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # –ü–æ–ª–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            full_filename = f"ras_results_{date_from}_{date_to}_{timestamp}.json"
            full_path = os.path.join(SAVE_DIR, full_filename)
            
            with open(full_path, 'w', encoding='utf-8') as f:
                json.dump({
                    'metadata': {
                        'date_from': date_from,
                        'date_to': date_to,
                        'total_attempts': len(results),
                        'session_stats': self.session_stats,
                        'timestamp': timestamp
                    },
                    'results': results
                }, f, ensure_ascii=False, indent=2)
            
            logger.info(f"üíæ –ü–æ–ª–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã: {full_path}")
            
            # –¢–æ–ª—å–∫–æ –¥–∞–Ω–Ω—ã–µ
            all_data = []
            for result in results:
                if 'data' in result and 'Data' in result['data']:
                    all_data.extend(result['data']['Data'])
            
            if all_data:
                data_filename = f"ras_data_{date_from}_{date_to}_{timestamp}.json"
                data_path = os.path.join(SAVE_DIR, data_filename)
                
                with open(data_path, 'w', encoding='utf-8') as f:
                    json.dump(all_data, f, ensure_ascii=False, indent=2)
                
                logger.info(f"üíæ –î–∞–Ω–Ω—ã–µ ({len(all_data)} –∑–∞–ø–∏—Å–µ–π): {data_path}")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")


# –ì–ª–∞–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è —É–¥–æ–±–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
def parse_ras_arbitr(date_from: str, date_to: str) -> List[Dict]:
    """
    –ü–∞—Ä—Å–∏–Ω–≥ ras.arbitr.ru
    
    Args:
        date_from: –î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ YYYY-MM-DD
        date_to: –î–∞—Ç–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ YYYY-MM-DD
        
    Returns:
        –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–∞—Ä—Å–∏–Ω–≥–∞
        
    Example:
        results = parse_ras_arbitr("2024-10-01", "2024-10-01")
    """
    scraper = RasArbitrScraper()
    return scraper.scrape_date_range(date_from, date_to)


def test_parsing():
    """
    –ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞ –∑–∞ –≤—á–µ—Ä–∞—à–Ω–∏–π –¥–µ–Ω—å
    """
    yesterday = (datetime.now() - timedelta(days=1)).strftime("%Y-%m-%d")
    
    logger.info(f"üß™ –¢–ï–°–¢–û–í–´–ô –ü–ê–†–°–ò–ù–ì –∑–∞ {yesterday}")
    results = parse_ras_arbitr(yesterday, yesterday)
    
    if results:
        logger.info(f"‚úÖ –¢–µ—Å—Ç —É—Å–ø–µ—à–µ–Ω: –ø–æ–ª—É—á–µ–Ω–æ {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        return True
    else:
        logger.error("‚ùå –¢–µ—Å—Ç –Ω–µ –ø—Ä–æ—à–µ–ª")
        return False


def parse_date_range_loop(start_date: str, end_date: str):
    """
    –ü–∞—Ä—Å–∏–Ω–≥ –ø–æ –¥–Ω—è–º –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ
    
    Args:
        start_date: –î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞ YYYY-MM-DD
        end_date: –î–∞—Ç–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è YYYY-MM-DD
    
    Example:
        results = parse_date_range_loop("2024-10-01", "2024-10-05")
    """
    current = datetime.strptime(start_date, "%Y-%m-%d")
    end = datetime.strptime(end_date, "%Y-%m-%d")
    
    day_num = 1
    all_results = []
    
    while current <= end:
        date_str = current.strftime("%Y-%m-%d")
        
        logger.info(f"\n\n{'#'*60}")
        logger.info(f"üìÖ –î–ï–ù–¨ {day_num}: {date_str}")
        logger.info(f"{'#'*60}\n")
        
        results = parse_ras_arbitr(date_str, date_str)
        all_results.extend(results)
        
        # –ê–Ω—Ç–∏–±–∞–Ω –ø–∞—É–∑–∞ –º–µ–∂–¥—É –¥–Ω—è–º–∏
        if current < end:
            pause = random.uniform(30, 60)
            logger.info(f"‚è≥ –ü–∞—É–∑–∞ –º–µ–∂–¥—É –¥–Ω—è–º–∏: {pause:.1f}s")
            time.sleep(pause)
        
        current += timedelta(days=1)
        day_num += 1
    
    logger.info(f"\n‚úÖ –ó–ê–í–ï–†–®–ï–ù–û: –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {day_num-1} –¥–Ω–µ–π, –ø–æ–ª—É—á–µ–Ω–æ {len(all_results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    return all_results


def download_pdfs_from_results(json_path: str, max_per_run: Optional[int] = None) -> None:
    """
    –û—Ç–∫—Ä—ã–≤–∞–µ—Ç RAS, –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç –ø–æ–∏—Å–∫ –ø–æ –¥–∞—Ç–∞–º –∏–∑ json –∏ —Å–∫–∞—á–∏–≤–∞–µ—Ç PDF –¥–ª—è –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤,
    –∫–ª–∏–∫–∞—è –ø–æ —Å—Ç—Ä–æ–∫–∞–º, –≥–¥–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç FileName/CaseNumber.
    """
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            payload = json.load(f)
    except Exception as e:
        logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å JSON: {e}")
        return

    results = payload.get('results') or []
    if not results:
        logger.warning("‚ö†Ô∏è –í JSON –Ω–µ—Ç —Å–µ–∫—Ü–∏–∏ results")
        return

    # –î–∞—Ç—ã –¥–ª—è —Ñ–æ—Ä–º—ã
    meta = payload.get('metadata') or {}
    date_from = meta.get('date_from')
    date_to = meta.get('date_to')
    if not date_from or not date_to:
        logger.warning("‚ö†Ô∏è –í metadata –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç date_from/date_to")

    # –°–æ–±–∏—Ä–∞–µ–º —Å–ø–∏—Å–æ–∫ —ç–ª–µ–º–µ–Ω—Ç–æ–≤
    items: List[Dict] = []
    for block in results:
        data = block.get('data') or {}
        result_obj = data.get('Result') or {}
        items.extend(result_obj.get('Items') or [])

    if not items:
        logger.info("‚ÑπÔ∏è –ü—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ Items ‚Äî –Ω–µ—á–µ–≥–æ —Å–∫–∞—á–∏–≤–∞—Ç—å")
        return

    if max_per_run is not None:
        items = items[:max_per_run]

    # –ó–∞–ø—É—Å–∫–∞–µ–º –±—Ä–∞—É–∑–µ—Ä
    scraper = RasArbitrScraper()
    scraper.parser = RasArbitrParser()
    scraper.parser.build_driver()
    scraper.prewarm_session()

    try:
        # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ —Ñ–æ—Ä–º—É –∏ –∑–∞–ø–æ–ª–Ω—è–µ–º –¥–∞—Ç—ã (–µ—Å–ª–∏ –µ—Å—Ç—å)
        scraper.parser.driver.get(RAS_HOME)
        scraper.parser.wait_ready()
        try:
            scraper.parser.driver.execute_script("window.location.hash='searchPrintForm';")
        except Exception:
            pass
        time.sleep(2)

        handler = RasSearchHandler(scraper.parser)
        handler.wait_for_spa_ready(timeout=30)
        if date_from and date_to:
            handler.fill_search_form(date_from, date_to)
            scraper.parser.clear_intercept_buffer()
            handler.submit_search()
            time.sleep(2)

        # –ü–µ—Ä–µ–±–∏—Ä–∞–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã –∏ –ø—ã—Ç–∞–µ–º—Å—è –∫–ª–∏–∫–Ω—É—Ç—å –ø–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–π —Å—Ç—Ä–æ–∫–µ –∏ —Å–∫–∞—á–∞—Ç—å PDF
        downloaded = 0
        for it in items:
            file_name = (it.get('FileName') or '').strip()
            case_num = (it.get('CaseNumber') or '').strip()
            if not file_name and not case_num:
                continue

            logger.info(f"üìÑ –ü–æ–∏—Å–∫ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è: {file_name or case_num}")

            # –ü–æ–ø—ã—Ç–∫–∞ –Ω–∞–π—Ç–∏ –ø–æ —Ç–µ–∫—Å—Ç—É FileName/CaseNumber –∏ –∫–ª–∏–∫–Ω—É—Ç—å –∏–º–µ–Ω–Ω–æ –ø–æ —Å—Å—ã–ª–∫–µ —Å—Ç—Ä–æ–∫–∏
            found = False
            search_texts = [t for t in [file_name, case_num] if t]
            for text in search_texts:
                try:
                    # –ò—â–µ–º —ç–ª–µ–º–µ–Ω—Ç, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π —Ç–µ–∫—Å—Ç
                    elem = WebDriverWait(scraper.parser.driver, 8).until(
                        EC.presence_of_element_located((By.XPATH, f"//*[contains(text(), '{text}')]"))
                    )
                    # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –±–ª–∏–∂–∞–π—à—É—é —Å—Å—ã–ª–∫—É –≤–Ω—É—Ç—Ä–∏ —Å—Ç—Ä–æ–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                    row = elem
                    for _ in range(5):
                        try:
                            # –ø–æ–¥–Ω–∏–º–∞–µ–º—Å—è –≤–≤–µ—Ä—Ö –∫ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—É —Å—Ç—Ä–æ–∫–∏
                            parent = row.find_element(By.XPATH, './..')
                            row = parent
                        except Exception:
                            break
                    link_el = None
                    try:
                        # –ß–∞—Å—Ç–æ –ø–µ—Ä–≤–∞—è —Å—Å—ã–ª–∫–∞ –≤–Ω—É—Ç—Ä–∏ —Å—Ç—Ä–æ–∫–∏ –≤–µ–¥–µ—Ç –Ω–∞ –∫–∞—Ä—Ç–æ—á–∫—É
                        anchors = row.find_elements(By.XPATH, ".//a[@href]")
                        if anchors:
                            link_el = anchors[0]
                    except Exception:
                        pass

                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–ø–∏—Å–æ–∫ –æ–∫–æ–Ω –¥–æ –∫–ª–∏–∫–∞
                    before_windows = set(scraper.parser.driver.window_handles)

                    # –ö–ª–∏–∫ –ø–æ —Å—Å—ã–ª–∫–µ —Å—Ç—Ä–æ–∫–∏, –µ—Å–ª–∏ –Ω–∞—à–ª–∏; –∏–Ω–∞—á–µ –ø–æ —Å–∞–º–æ–º—É —ç–ª–µ–º–µ–Ω—Ç—É
                    try:
                        target = link_el or elem
                        scraper.parser.driver.execute_script("arguments[0].scrollIntoView({block:'center'});", target)
                    except Exception:
                        pass
                    time.sleep(0.4)
                    try:
                        (link_el or elem).click()
                    except Exception:
                        scraper.parser.driver.execute_script("arguments[0].click();", (link_el or elem))

                    # –ñ–¥–µ–º –æ—Ç–∫—Ä—ã—Ç–∏—è –Ω–æ–≤–æ–π –≤–∫–ª–∞–¥–∫–∏ –∏–ª–∏ –ø–æ—è–≤–ª–µ–Ω–∏—è –º–æ–¥–∞–ª—å–Ω–æ–≥–æ –æ–∫–Ω–∞/–∫–Ω–æ–ø–æ–∫ PDF
                    time.sleep(1.0)
                    after_windows = set(scraper.parser.driver.window_handles)
                    opened_new = list(after_windows - before_windows)
                    switched = False
                    if opened_new:
                        # –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ –Ω–æ–≤—É—é –≤–∫–ª–∞–¥–∫—É (—á–∞—Å—Ç–æ –≤–µ–¥–µ—Ç –Ω–∞ kad.arbitr.ru)
                        new_handle = opened_new[-1]
                        scraper.parser.driver.switch_to.window(new_handle)
                        switched = True
                        # –î–ª—è KAD –≤—ã—Å—Ç–∞–≤–∏–º —Ä–µ—Ñ–µ—Ä–µ—Ä –∏ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –Ω–∞–≤–∏–≥–∞—Ü–∏–∏
                        try:
                            scraper.parser.driver.execute_cdp_cmd("Network.setExtraHTTPHeaders", {
                                "headers": {
                                    "Referer": KAD_HOME,
                                    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,application/pdf;q=0.9,*/*;q=0.8",
                                    "Accept-Language": "ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7",
                                }
                            })
                        except Exception:
                            pass

                    # –ò—â–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã —Å–∫–∞—á–∏–≤–∞–Ω–∏—è PDF –≤ —Ç–µ–∫—É—â–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
                    def try_download_in_context() -> bool:
                        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä—è–º—ã–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ Pdf
                        candidates = []
                        try:
                            candidates += scraper.parser.driver.find_elements(By.XPATH, "//a[contains(@href,'/Document/Pdf/')]")
                        except Exception:
                            pass
                        try:
                            candidates += scraper.parser.driver.find_elements(By.XPATH, "//a[contains(translate(text(),'PDF','pdf'),'pdf')]")
                        except Exception:
                            pass
                        try:
                            candidates += scraper.parser.driver.find_elements(By.XPATH, "//button[contains(translate(text(),'–°–∫–∞—á–∞—Ç—åPDF','—Å–∫–∞—á–∞—Ç—åpdf'),'—Å–∫–∞—á–∞—Ç—å') or contains(translate(text(),'PDF','pdf'),'pdf')]")
                        except Exception:
                            pass

                        if not candidates:
                            return False

                        link = candidates[0]
                        try:
                            scraper.parser.driver.execute_script("arguments[0].scrollIntoView({block:'center'});", link)
                        except Exception:
                            pass
                        time.sleep(0.4)
                        try:
                            link.click()
                        except Exception:
                            try:
                                scraper.parser.driver.execute_script("arguments[0].click();", link)
                            except Exception:
                                return False

                        # –ü–µ—Ä–µ–¥ –æ–∂–∏–¥–∞–Ω–∏–µ–º —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –ø—Ä–æ–≤–µ—Ä–∏–º, —á—Ç–æ CDP –≤–∏–¥–µ–ª PDF
                        pdf_resp = scraper.parser.wait_for_pdf_via_cdp(timeout=5)
                        # –û–∂–∏–¥–∞–µ–º —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ
                        try:
                            saved = scraper.parser.wait_download_finished(SAVE_DIR, timeout=240)
                            logger.info(f"‚úÖ PDF —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {saved}")
                            return True
                        except Exception as e:
                            logger.warning(f"‚ö†Ô∏è –ù–µ –¥–æ–∂–¥–∞–ª–∏—Å—å —Å–∫–∞—á–∏–≤–∞–Ω–∏—è: {e}")
                            return False

                    # –ü—ã—Ç–∞–µ–º—Å—è —Å–∫–∞—á–∞—Ç—å –≤ —Ç–µ–∫—É—â–µ–º –æ–∫–Ω–µ
                    if try_download_in_context():
                        downloaded += 1
                        found = True
                    else:
                        # –ò–Ω–æ–≥–¥–∞ —Å—Å—ã–ª–∫–∞ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –ø–æ—Å–ª–µ –¥–æ–ø. –∫–ª–∏–∫–æ–≤ –ø–æ –≤–∫–ª–∞–¥–∫–∞–º/–∫–Ω–æ–ø–∫–∞–º –≤–Ω—É—Ç—Ä–∏ –∫–∞—Ä—Ç–æ—á–∫–∏. –ü–æ–ø—Ä–æ–±—É–µ–º –∫–ª–∏–∫–Ω—É—Ç—å –æ—á–µ–≤–∏–¥–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã.
                        try:
                            tabs = scraper.parser.driver.find_elements(By.XPATH, "//a[contains(translate(text(),'–î–û–ö–£–ú–ï–ù–¢–´PDF','–¥–æ–∫—É–º–µ–Ω—Ç—ãpdf'),'–¥–æ–∫—É–º–µ–Ω—Ç') or contains(translate(text(),'PDF','pdf'),'pdf')]")
                            if tabs:
                                try:
                                    tabs[0].click()
                                except Exception:
                                    scraper.parser.driver.execute_script("arguments[0].click();", tabs[0])
                                time.sleep(0.8)
                                if try_download_in_context():
                                    downloaded += 1
                                    found = True
                        except Exception:
                            pass

                    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –Ω–∞ –∏—Å—Ö–æ–¥–Ω—É—é –≤–∫–ª–∞–¥–∫—É, –µ—Å–ª–∏ –ø–µ—Ä–µ–∫–ª—é—á–∞–ª–∏—Å—å
                    if switched:
                        try:
                            # –ó–∞–∫—Ä—ã–≤–∞–µ–º –Ω–æ–≤—É—é –≤–∫–ª–∞–¥–∫—É, —á—Ç–æ–±—ã –Ω–µ —Ä–∞–∑—Ä–∞—Å—Ç–∞–ª–∏—Å—å
                            scraper.parser.driver.close()
                        except Exception:
                            pass
                        try:
                            base_handle = list(before_windows)[-1] if before_windows else scraper.parser.driver.window_handles[0]
                            scraper.parser.driver.switch_to.window(base_handle)
                        except Exception:
                            pass

                    if found:
                        break
                except Exception:
                    continue

            # –ü–∞—É–∑–∞ –º–µ–∂–¥—É —Ñ–∞–π–ª–∞–º–∏ —Å –∞–Ω—Ç–∏–±–∞–Ω-–¥–∂–∏—Ç—Ç–µ—Ä–æ–º
            time.sleep(max(0, BASE_DELAY + random.uniform(-JITTER, JITTER)))

        logger.info(f"üìä –ò—Ç–æ–≥ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è PDF: {downloaded}/{len(items)}")

    finally:
        try:
            scraper.parser.driver.quit()
        except Exception:
            pass


def scrape_and_download(date_from: str, date_to: str, max_per_run: Optional[int] = None) -> None:
    """
    –û–¥–∏–Ω —à–∞–≥: –≤—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–∏—Å–∫ –≤–Ω—É—Ç—Ä–∏ –±—Ä–∞—É–∑–µ—Ä–∞ –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–µ –¥–∞—Ç—ã –∏
    —Å—Ä–∞–∑—É –ø—ã—Ç–∞–µ—Ç—Å—è —Å–∫–∞—á–∞—Ç—å PDF –¥–ª—è –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.
    """
    scraper = RasArbitrScraper()
    scraper.parser = RasArbitrParser()
    scraper.parser.build_driver()
    scraper.prewarm_session()

    try:
        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫ –∏ –ø–æ–ª—É—á–∞–µ–º JSON (—á–µ—Ä–µ–∑ CDP/JS/curl_cffi –≤–Ω—É—Ç—Ä–∏)
        result = scraper.search_by_date_range(date_from, date_to)
        if not result or not result.get('data'):
            logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞")
            return

        data = result['data']
        res_obj = (data.get('Result') or {})
        items = res_obj.get('Items') or []
        if not items:
            logger.info("‚ÑπÔ∏è –ü—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ Items ‚Äî –Ω–µ—á–µ–≥–æ —Å–∫–∞—á–∏–≤–∞—Ç—å")
            return
        if max_per_run is not None:
            items = items[:max_per_run]

        driver = scraper.parser.driver

        def try_download_in_context() -> bool:
            candidates = []
            try:
                candidates += driver.find_elements(By.XPATH, "//a[contains(@href,'/Document/Pdf/')]")
            except Exception:
                pass
            try:
                candidates += driver.find_elements(By.XPATH, "//a[contains(translate(text(),'PDF','pdf'),'pdf')]")
            except Exception:
                pass
            try:
                candidates += driver.find_elements(By.XPATH, "//button[contains(translate(text(),'–°–∫–∞—á–∞—Ç—åPDF','—Å–∫–∞—á–∞—Ç—åpdf'),'—Å–∫–∞—á–∞—Ç—å') or contains(translate(text(),'PDF','pdf'),'pdf')]")
            except Exception:
                pass
            if not candidates:
                return False
            link = candidates[0]
            try:
                driver.execute_script("arguments[0].scrollIntoView({block:'center'});", link)
            except Exception:
                pass
            time.sleep(0.4)
            try:
                link.click()
            except Exception:
                try:
                    driver.execute_script("arguments[0].click();", link)
                except Exception:
                    return False
            # –ñ–¥–µ–º PDF —Å–∏–≥–Ω–∞–ª –∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
            _ = scraper.parser.wait_for_pdf_via_cdp(timeout=5)
            try:
                saved = scraper.parser.wait_download_finished(PDF_DIR, timeout=240)
                logger.info(f"‚úÖ PDF —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {saved}")
                return True
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –ù–µ –¥–æ–∂–¥–∞–ª–∏—Å—å —Å–∫–∞—á–∏–≤–∞–Ω–∏—è: {e}")
                return False

        downloaded = 0
        for it in items:
            file_name = (it.get('FileName') or '').strip()
            case_num = (it.get('CaseNumber') or '').strip()
            search_texts = [t for t in [file_name, case_num] if t]

            logger.info(f"üìÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ —ç–ª–µ–º–µ–Ω—Ç–∞: {file_name or case_num}")

            opened = False
            for text in search_texts:
                try:
                    elem = WebDriverWait(driver, 8).until(
                        EC.presence_of_element_located((By.XPATH, f"//*[contains(text(), '{text}')]"))
                    )
                    # –ü–æ–¥–Ω–∏–º–∞–µ–º—Å—è –∫ —Å—Ç—Ä–æ–∫–µ –∏ –∏—â–µ–º —Å—Å—ã–ª–∫—É
                    row = elem
                    for _ in range(5):
                        try:
                            row = row.find_element(By.XPATH, './..')
                        except Exception:
                            break
                    link_el = None
                    try:
                        anchors = row.find_elements(By.XPATH, ".//a[@href]")
                        if anchors:
                            link_el = anchors[0]
                    except Exception:
                        pass

                    before_windows = set(driver.window_handles)
                    target = link_el or elem
                    try:
                        driver.execute_script("arguments[0].scrollIntoView({block:'center'});", target)
                    except Exception:
                        pass
                    time.sleep(0.4)
                    try:
                        target.click()
                    except Exception:
                        driver.execute_script("arguments[0].click();", target)

                    # –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ –Ω–æ–≤—É—é –≤–∫–ª–∞–¥–∫—É (–µ—Å–ª–∏ –æ—Ç–∫—Ä—ã–ª–∞—Å—å)
                    time.sleep(1.0)
                    after_windows = set(driver.window_handles)
                    opened_new = list(after_windows - before_windows)
                    switched = False
                    if opened_new:
                        driver.switch_to.window(opened_new[-1])
                        switched = True
                        try:
                            scraper.parser.driver.execute_cdp_cmd("Network.setExtraHTTPHeaders", {
                                "headers": {
                                    "Referer": KAD_HOME,
                                    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,application/pdf;q=0.9,*/*;q=0.8",
                                    "Accept-Language": "ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7",
                                }
                            })
                        except Exception:
                            pass

                    if try_download_in_context():
                        downloaded += 1
                        opened = True
                    else:
                        # –î–æ–ø. –ø–æ–ø—ã—Ç–∫–∞: –ø–µ—Ä–µ–π—Ç–∏ –Ω–∞ –≤–∫–ª–∞–¥–∫—É/—Å–µ–∫—Ü–∏—é ¬´–î–æ–∫—É–º–µ–Ω—Ç—ã¬ª –∏ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —Å–Ω–æ–≤–∞
                        try:
                            tabs = driver.find_elements(By.XPATH, "//a[contains(translate(text(),'–î–û–ö–£–ú–ï–ù–¢–´PDF','–¥–æ–∫—É–º–µ–Ω—Ç—ãpdf'),'–¥–æ–∫—É–º–µ–Ω—Ç') or contains(translate(text(),'PDF','pdf'),'pdf')]")
                            if tabs:
                                try:
                                    tabs[0].click()
                                except Exception:
                                    driver.execute_script("arguments[0].click();", tabs[0])
                                time.sleep(0.8)
                                if try_download_in_context():
                                    downloaded += 1
                                    opened = True
                        except Exception:
                            pass

                    # –ó–∞–∫—Ä—ã–≤–∞–µ–º –≤–∫–ª–∞–¥–∫—É –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è
                    if switched:
                        try:
                            driver.close()
                        except Exception:
                            pass
                        try:
                            base_handle = list(before_windows)[-1] if before_windows else driver.window_handles[0]
                            driver.switch_to.window(base_handle)
                        except Exception:
                            pass

                    if opened:
                        break
                except Exception:
                    continue

            # –ü–∞—É–∑–∞ –∞–Ω—Ç–∏–±–∞–Ω
            time.sleep(max(0, BASE_DELAY + random.uniform(-JITTER, JITTER)))

        logger.info(f"üìä –ò—Ç–æ–≥ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è PDF: {downloaded}/{len(items)}")

    finally:
        try:
            scraper.parser.driver.quit()
        except Exception:
            pass

def download_pdf_list(pdf_urls: List[str], max_retries: int = 2):
    """
    –ü–∞–∫–µ—Ç–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ PDF —Å –∞–Ω—Ç–∏–±–∞–Ω-—Å—Ç—Ä–∞—Ç–µ–≥–∏–µ–π (–∏–∑ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤)
    
    Args:
        pdf_urls: –°–ø–∏—Å–æ–∫ URL PDF —Ñ–∞–π–ª–æ–≤
        max_retries: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ –Ω–∞ —Ñ–∞–π–ª
    """
    parser = RasArbitrParser()
    parser.build_driver()
    
    success = 0
    fail = 0
    
    try:
        # –ü—Ä–æ–≥—Ä–µ–≤ —Å–µ—Å—Å–∏–∏
        logger.info("üî• –ü—Ä–æ–≥—Ä–µ–≤ —Å–µ—Å—Å–∏–∏ –¥–ª—è PDF —Å–∫–∞—á–∏–≤–∞–Ω–∏—è...")
        parser.driver.get(RAS_HOME)
        parser.wait_ready()
        parser.humanize_behavior(moves=random.randint(6, 12))
        time.sleep(random.uniform(1.5, 3.0))
        
        for idx, url in enumerate(pdf_urls, 1):
            logger.info(f"üìÑ –°–∫–∞—á–∏–≤–∞–Ω–∏–µ PDF {idx}/{len(pdf_urls)}: {url}")
            
            # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–π –ø—Ä–æ–≥—Ä–µ–≤
            if (idx % PREWARM_EVERY) == 0:
                logger.info("üî• –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–π –ø—Ä–æ–≥—Ä–µ–≤...")
                parser.driver.get(RAS_HOME)
                parser.wait_ready()
                parser.humanize_behavior(moves=random.randint(5, 10))
                time.sleep(random.uniform(0.8, 1.5))
            
            # –ü–æ–ø—ã—Ç–∫–∏ —Å –±—ç–∫–æ—Ñ—Ñ–æ–º
            ok = False
            backoff = 8
            
            for attempt in range(1, max_retries + 1):
                try:
                    before = set(os.listdir(SAVE_DIR))
                    parser.driver.get(url)
                    time.sleep(1.5)  # –î–∞—ë–º —Å–µ—Ç–∏ —Å—Ç–∞—Ä—Ç–∞–Ω—É—Ç—å
                    
                    saved = parser.wait_download_finished(SAVE_DIR, timeout=240)
                    logger.info(f"‚úÖ PDF —Å–∫–∞—á–∞–Ω: {saved}")
                    ok = True
                    break
                    
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è –ü–æ–ø—ã—Ç–∫–∞ {attempt} –Ω–µ —É–¥–∞–ª–∞—Å—å: {e}")
                    if attempt < max_retries:
                        sleep_s = backoff + random.uniform(0, 4)
                        logger.info(f"‚è≥ –ü–∞—É–∑–∞ {sleep_s:.1f}s –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–æ–º...")
                        time.sleep(sleep_s)
                        backoff *= 2
                        
                        # –°–±—Ä–æ—Å –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –∏ –ø—Ä–æ–≥—Ä–µ–≤
                        parser.driver.execute_cdp_cmd("Network.setExtraHTTPHeaders", {
                            "headers": {
                                "Referer": "https://ras.arbitr.ru/",
                                "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,application/pdf;q=0.9,*/*;q=0.8",
                                "Accept-Language": "ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7",
                                "Upgrade-Insecure-Requests": "1",
                                "Sec-Fetch-Site": "same-origin",
                                "Sec-Fetch-Mode": "navigate",
                                "Sec-Fetch-Dest": "document",
                                "Connection": "keep-alive"
                            }
                        })
                        parser.driver.get(RAS_HOME)
                        parser.wait_ready()
                        parser.humanize_behavior(moves=random.randint(5, 10))
                        time.sleep(random.uniform(0.8, 1.5))
            
            if ok:
                success += 1
            else:
                fail += 1
            
            # –ë–∞–∑–æ–≤–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É —Ñ–∞–π–ª–∞–º–∏
            delay = max(0, BASE_DELAY + random.uniform(-JITTER, JITTER))
            time.sleep(delay)
            
            # –î–ª–∏–Ω–Ω–∞—è –ø–∞—É–∑–∞ –∫–∞–∂–¥—ã–µ N —Ñ–∞–π–ª–æ–≤
            if (idx % LONG_PAUSE_EVERY) == 0:
                extra = random.uniform(*LONG_PAUSE_RANGE)
                logger.info(f"‚è≥ –î–ª–∏–Ω–Ω–∞—è –ø–∞—É–∑–∞: {extra:.1f}s")
                time.sleep(extra)
        
        logger.info(f"üìä –ò–¢–û–ì–û PDF: –£—Å–ø–µ—à–Ω–æ={success}, –û—à–∏–±–æ–∫={fail}")
        
    finally:
        if parser.driver:
            parser.driver.quit()


if __name__ == "__main__":
    print("üöÄ RAS Arbitr Parser v2.0 - –ü–û–õ–ù–ê–Ø –í–ï–†–°–ò–Ø")
    print("="*60)
    print("‚úÖ –£—á—Ç–µ–Ω—ã –í–°–ï —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –∏–∑ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤:")
    print("  - –ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã (#sug-dates label.from/to input.anyway_position_top)")
    print("  - Fetch.enable –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø–µ—Ä–µ—Ö–≤–∞—Ç–∞")
    print("  - –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ PDF —Å –æ–∂–∏–¥–∞–Ω–∏–µ–º .crdownload")
    print("  - –ü–∞–∫–µ—Ç–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —Å –∞–Ω—Ç–∏–±–∞–Ω-—Å—Ç—Ä–∞—Ç–µ–≥–∏–µ–π")
    print("  - –ß–ï–¢–´–†–ï –º–µ—Ç–æ–¥–∞ –ø–µ—Ä–µ—Ö–≤–∞—Ç–∞: CDP Network ‚Üí Fetch ‚Üí JS ‚Üí curl_cffi")
    print("  - curl_cffi —Å impersonation –¥–ª—è –≤–Ω–µ—à–Ω–∏—Ö POST (–∑–∞–ø–∞—Å–Ω–æ–π)")
    print("="*60)
    print("1. –¢–µ—Å—Ç: test_parsing()")
    print("2. –ü–∞—Ä—Å–∏–Ω–≥: parse_ras_arbitr('2024-10-01', '2024-10-01')")
    print("3. –î–∏–∞–ø–∞–∑–æ–Ω: parse_date_range_loop('2024-10-01', '2024-10-05')")
    print("4. PDF: download_pdf_list(['url1', 'url2'])")
    print("="*60)
    
    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ PDF, –µ—Å–ª–∏ –µ—Å—Ç—å —Å–ø–∏—Å–æ–∫ URL –≤ res/pdf_urls.txt
    urls_file = Path(SAVE_DIR) / "pdf_urls.txt"
    if urls_file.exists():
        try:
            with open(urls_file, "r", encoding="utf-8") as f:
                pdf_urls = [line.strip() for line in f if line.strip() and not line.strip().startswith("#")]
            if pdf_urls:
                logger.info(f"üì• –ù–∞–π–¥–µ–Ω–æ {len(pdf_urls)} PDF —Å—Å—ã–ª–æ–∫ –≤ {urls_file}. –ó–∞–ø—É—Å–∫–∞—é —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ...")
                download_pdf_list(pdf_urls)
            else:
                logger.info("‚ÑπÔ∏è –§–∞–π–ª pdf_urls.txt –ø—É—Å—Ç. –ó–∞–ø—É—Å–∫–∞—é —Ç–µ—Å—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞.")
                test_parsing()
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ PDF: {e}")
            test_parsing()
    else:
        # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∑–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –ø–∞—Ä—Å–∏–Ω–≥
        test_parsing()
